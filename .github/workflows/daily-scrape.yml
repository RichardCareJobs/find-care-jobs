# .github/workflows/daily-scrape.yml
name: Daily Job Scrape

permissions:
  contents: write    # ⇦ allow push of updated CSVs

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          persist-credentials: true   # ⇦ this makes GITHUB_TOKEN available to push
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "18"
      - name: Install dependencies
        run: npm install
      - name: Run daily scrape
        run: node scrape/scrape.js
      - name: List all CSVs
        run: |
          echo "Workspace at $(pwd)"
          find "$(pwd)" -type f -name '*.csv' -exec echo "  → {}" ';'
      - name: "Debug: show CSV head"
        run: |
          echo "--- job_listings.csv head ---"
          head -n 5 scrape/job_listings.csv || echo "(missing)"
          echo "--- sponsored_jobs.csv head ---"
          head -n 5 scrape/sponsored_jobs.csv || echo "(missing)"
      - name: Archive CSVs
        run: >
          TIMESTAMP=$(date -u +'%Y-%m-%d_%H%M')

          mkdir -p archive

          cp scrape/job_listings.csv  archive/job_listings_${TIMESTAMP}.csv

          cp scrape/sponsored_jobs.csv archive/sponsored_jobs_${TIMESTAMP}.csv || echo "no sponsored file"

          
      - name: Commit updated + archived CSVs
        uses: EndBug/add-and-commit@v9
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}   # ⇦ ensure the token is injected
        with:
          add: "scrape/job_listings.csv scrape/sponsored_jobs.csv archive/*.csv"
          commit: "--allow-empty"                     # optional
          message: "chore: automated daily scrape & archive"

